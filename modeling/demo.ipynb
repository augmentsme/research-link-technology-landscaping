{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7393660c",
   "metadata": {},
   "source": [
    "# Research Keywords Analysis Demo\n",
    "\n",
    "This notebook demonstrates how to analyze research grant keywords using the two-step harmonisation approach:\n",
    "\n",
    "1. **Load extracted keywords** from evaluation results\n",
    "2. **Load two-step harmonisation results** (latest approach) \n",
    "3. **Apply harmonisation mappings** to keywords\n",
    "4. **Join with grants metadata** for comprehensive analysis\n",
    "\n",
    "The two-step approach avoids token limits by first identifying groups of similar keywords, then harmonising each group individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35562c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import pandas as pd\n",
    "from inspect_ai.analysis import messages_df, evals_df, samples_df\n",
    "from tasks import (\n",
    "    load_extracted_keywords, load_grants_data, \n",
    "    combine_two_step_harmonisation_results,\n",
    "    LOGS_DIR, DATA_DIR, GRANTS_FILE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483cf1c5",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define the core functions for loading and processing evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "456eec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_ids(evals):\n",
    "    \"\"\"Return extract eval ID from evals dataframe.\"\"\"\n",
    "    eval_ids = {}\n",
    "    \n",
    "    if not evals[evals.task_name == \"extract\"].empty:\n",
    "        eval_ids['extract'] = evals[evals.task_name == \"extract\"].eval_id.item()\n",
    "    \n",
    "    return eval_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df55cb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages_and_samples(logs_dir):\n",
    "    \"\"\"Load and index messages and samples dataframes.\"\"\"\n",
    "    messages = messages_df(logs_dir).set_index('message_id')\n",
    "    samples = samples_df(logs_dir).set_index('sample_id')\n",
    "    return messages, samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320a6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_extracted_keywords(messages, samples, extract_id):\n",
    "    \"\"\"Return extracted keywords dataframe joined with sample metadata.\"\"\"\n",
    "    extracted_samples = samples[samples.eval_id == extract_id]\n",
    "    extracted_messages = messages[(messages.eval_id == extract_id) & (messages.role == \"assistant\")]\n",
    "    extracted_keywords_df = pd.json_normalize(extracted_messages.content.map(json.loads)).set_index(extracted_messages.sample_id)\n",
    "    extracted_keywords_df = extracted_keywords_df.join(extracted_samples.metadata_grant_id)\n",
    "    return extracted_keywords_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d56ed2",
   "metadata": {},
   "source": [
    "## Harmonisation Functions\n",
    "\n",
    "Functions to load and process the two-step harmonisation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "170668c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_harmonised_keywords(logs_dir):\n",
    "    \"\"\"\n",
    "    Get harmonised keywords using the latest two-step approach.\n",
    "    Modified to return original keywords instead of indices.\n",
    "    \n",
    "    Args:\n",
    "        logs_dir: Directory containing evaluation logs\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with harmonised keyword mappings or None if not available\n",
    "    \"\"\"\n",
    "    from tasks import load_keyword_groups, load_group_harmonisations, load_extracted_keywords\n",
    "    \n",
    "    # Load results from both steps\n",
    "    keyword_groups = load_keyword_groups(logs_dir)\n",
    "    group_harmonisations = load_group_harmonisations(logs_dir)\n",
    "    \n",
    "    if not keyword_groups or not group_harmonisations:\n",
    "        return None\n",
    "    \n",
    "    # Load original keywords\n",
    "    all_keywords = load_extracted_keywords(logs_dir)\n",
    "    flat_keywords = [kw for sublist in all_keywords.values() for kw in sublist]\n",
    "    unique_keywords = sorted(set(flat_keywords))\n",
    "    \n",
    "    # Build result with original keywords instead of indices\n",
    "    keyword_mappings = []\n",
    "    string_mappings = {}\n",
    "    \n",
    "    for group_indices in keyword_groups:\n",
    "        if not group_indices:\n",
    "            continue\n",
    "            \n",
    "        # Get the harmonised keyword for this group\n",
    "        if group_indices[0] < len(unique_keywords):\n",
    "            first_keyword = unique_keywords[group_indices[0]]\n",
    "            harmonised_keyword = group_harmonisations.get(first_keyword)\n",
    "            \n",
    "            if harmonised_keyword:\n",
    "                # Create list of original keywords for this group\n",
    "                original_keywords = [unique_keywords[idx] for idx in group_indices if 0 <= idx < len(unique_keywords)]\n",
    "                \n",
    "                mapping = {\n",
    "                    'original': original_keywords,\n",
    "                    'harmonised': harmonised_keyword\n",
    "                }\n",
    "                keyword_mappings.append(mapping)\n",
    "                \n",
    "                # Also create string mappings for backward compatibility\n",
    "                for kw in original_keywords:\n",
    "                    string_mappings[kw] = harmonised_keyword\n",
    "    \n",
    "    return {\n",
    "        \"keyword_mappings\": string_mappings,  # String-based mapping for compatibility\n",
    "        \"original_keyword_mappings\": keyword_mappings  # New format with original keywords\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ff24ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_with_grants(extracted_keywords_df, grants_file):\n",
    "    \"\"\"Join extracted keywords dataframe with grants dataframe.\"\"\"\n",
    "    grants_df = load_grants_data(grants_file, as_dataframe=True)\n",
    "    results = extracted_keywords_df.join(grants_df, on='metadata_grant_id', how='left')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae4ff8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_harmonisation(results, harmonised_keywords):\n",
    "    \"\"\"Apply harmonisation mappings to keywords in results dataframe.\"\"\"\n",
    "    if not harmonised_keywords or 'keyword_mappings' not in harmonised_keywords:\n",
    "        return results\n",
    "        \n",
    "    keyword_mappings = harmonised_keywords['keyword_mappings']\n",
    "    \n",
    "    # Apply harmonisation to each keyword category\n",
    "    for column in ['keywords', 'methodology_keywords', 'application_keywords', 'technology_keywords']:\n",
    "        if column in results.columns:\n",
    "            results[f'{column}_harmonised'] = results[column].map(\n",
    "                lambda x: [keyword_mappings.get(kw, kw) for kw in x] if x else []\n",
    "            )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91488c84",
   "metadata": {},
   "source": [
    "## Load and Process Data\n",
    "\n",
    "Execute the main analysis pipeline to load evaluation data and apply harmonisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a9f03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available evaluations: ['extract']\n",
      "✓ Found keyword extraction results\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation data\n",
    "evals = evals_df(LOGS_DIR)\n",
    "eval_ids = get_eval_ids(evals)\n",
    "\n",
    "print(f\"Available evaluations: {list(eval_ids.keys())}\")\n",
    "\n",
    "if 'extract' not in eval_ids:\n",
    "    print(\"❌ No keyword extraction results found. Run: inspect eval modeling/tasks.py@extract\")\n",
    "else:\n",
    "    print(\"✓ Found keyword extraction results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7feaf8a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded extracted keywords for 100 grants\n",
      "Keyword categories: ['keywords', 'methodology_keywords', 'application_keywords', 'technology_keywords']\n"
     ]
    }
   ],
   "source": [
    "# Load and process extracted keywords\n",
    "messages, samples = get_messages_and_samples(LOGS_DIR)\n",
    "extracted_keywords_df = process_extracted_keywords(messages, samples, eval_ids['extract'])\n",
    "\n",
    "print(f\"✓ Loaded extracted keywords for {len(extracted_keywords_df)} grants\")\n",
    "print(f\"Keyword categories: {[col for col in extracted_keywords_df.columns if col != 'metadata_grant_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b347a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded harmonisation results:\n",
      "  - 73 keyword mappings\n",
      "  - 37 harmonisation groups\n",
      "  - Original keywords: 73\n",
      "  - Harmonised keywords: 37\n",
      "  - Consolidation ratio: 1.97x\n"
     ]
    }
   ],
   "source": [
    "# Load harmonisation results\n",
    "harmonised_keywords = get_harmonised_keywords(LOGS_DIR)\n",
    "\n",
    "if harmonised_keywords:\n",
    "    keyword_mappings = harmonised_keywords.get('keyword_mappings', {})\n",
    "    original_mappings = harmonised_keywords.get('original_keyword_mappings', [])\n",
    "    \n",
    "    print(f\"✓ Loaded harmonisation results:\")\n",
    "    print(f\"  - {len(keyword_mappings)} keyword mappings\")\n",
    "    print(f\"  - {len(original_mappings)} harmonisation groups\")\n",
    "    \n",
    "    # Show statistics\n",
    "    unique_harmonised = len(set(keyword_mappings.values()))\n",
    "    consolidation_ratio = len(keyword_mappings) / unique_harmonised if unique_harmonised > 0 else 0\n",
    "    print(f\"  - Original keywords: {len(keyword_mappings)}\")\n",
    "    print(f\"  - Harmonised keywords: {unique_harmonised}\")\n",
    "    print(f\"  - Consolidation ratio: {consolidation_ratio:.2f}x\")\n",
    "else:\n",
    "    print(\"⚠️ No harmonisation results found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "318a356e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Joined with grant metadata\n",
      "✓ Applied harmonisation to keywords\n",
      "Final dataset shape: (100, 15)\n"
     ]
    }
   ],
   "source": [
    "# Join with grants data and apply harmonisation\n",
    "results = join_with_grants(extracted_keywords_df, GRANTS_FILE)\n",
    "print(f\"✓ Joined with grant metadata\")\n",
    "\n",
    "if harmonised_keywords:\n",
    "    results = apply_harmonisation(results, harmonised_keywords)\n",
    "    print(f\"✓ Applied harmonisation to keywords\")\n",
    "\n",
    "print(f\"Final dataset shape: {results.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ebd491",
   "metadata": {},
   "source": [
    "## Explore Results\n",
    "\n",
    "Examine the harmonised keyword structure and sample results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "292012b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      "  - keywords\n",
      "  - methodology_keywords\n",
      "  - application_keywords\n",
      "  - technology_keywords\n",
      "  - metadata_grant_id\n",
      "  - title\n",
      "  - grant_summary\n",
      "  - funder\n",
      "  - funding_amount\n",
      "  - funding_scheme\n",
      "  - status\n",
      "  - keywords_harmonised\n",
      "  - methodology_keywords_harmonised\n",
      "  - application_keywords_harmonised\n",
      "  - technology_keywords_harmonised\n"
     ]
    }
   ],
   "source": [
    "# Display dataset info\n",
    "print(\"Available columns:\")\n",
    "for col in results.columns:\n",
    "    print(f\"  - {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "182e895c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample harmonisation groups:\n",
      "\n",
      "1. ['3-D imaging software', '3D volumetric image reconstruction', '3D volumetric imaging system'] → '3D Volumetric Imaging'\n",
      "\n",
      "2. ['3-D seismic modeling', '3-D seismic structure'] → '3D seismic structure'\n",
      "\n",
      "3. ['3D geological modelling'] → '3D geological modelling'\n",
      "\n",
      "4. ['3D laser scanning', 'LiDAR scanning', 'LiDAR terrain mapping'] → 'LiDAR scanning'\n",
      "\n",
      "5. ['3D peptide structure determination'] → '3D peptide structure determination'\n"
     ]
    }
   ],
   "source": [
    "# Show sample harmonisation mappings\n",
    "if harmonised_keywords and 'original_keyword_mappings' in harmonised_keywords:\n",
    "    print(\"Sample harmonisation groups:\")\n",
    "    for i, mapping in enumerate(harmonised_keywords['original_keyword_mappings'][:5]):\n",
    "        original_list = mapping['original']\n",
    "        harmonised = mapping['harmonised']\n",
    "        print(f\"\\n{i+1}. {original_list} → '{harmonised}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "673a1890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample grant:\n",
      "Title: Industrial Transformation Training Centres - Grant ID: IC230100035...\n",
      "Funder: Australian Research Council\n",
      "Funding: $5,000,000.0\n",
      "\n",
      "Original keywords: ['Critical resources', 'Critical minerals', 'Mineral systems science']...\n",
      "Harmonised keywords: ['Critical resources', 'Critical minerals', 'Mineral systems science']...\n"
     ]
    }
   ],
   "source": [
    "# Show sample grant with keywords\n",
    "if not results.empty:\n",
    "    sample = results.iloc[0]\n",
    "    print(\"Sample grant:\")\n",
    "    print(f\"Title: {sample['title'][:100]}...\")\n",
    "    print(f\"Funder: {sample.get('funder', 'N/A')}\")\n",
    "    print(f\"Funding: ${sample.get('funding_amount', 'N/A'):,}\" if sample.get('funding_amount') else \"Funding: N/A\")\n",
    "    \n",
    "    print(f\"\\nOriginal keywords: {sample['keywords'][:3]}...\")\n",
    "    if 'keywords_harmonised' in results.columns:\n",
    "        print(f\"Harmonised keywords: {sample['keywords_harmonised'][:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07faf795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database created: /Users/luhancheng/Desktop/research-link-technology-landscaping/modeling/../data/research_keywords.db\n",
      "📊 100 grants\n",
      "🏷️ 37 harmonised keywords\n",
      "🔗 61 grant-keyword links\n"
     ]
    }
   ],
   "source": [
    "# Create SQLite database with all tables\n",
    "import sqlite3\n",
    "import uuid\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Database setup\n",
    "db_path = Path(\"../data/research_keywords.db\")\n",
    "db_path.parent.mkdir(exist_ok=True)\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "try:\n",
    "    # 1. Create grants table\n",
    "    grants_table = results[['metadata_grant_id', 'title', 'grant_summary', 'funder', \n",
    "                           'funding_amount', 'funding_scheme', 'status']].copy()\n",
    "    grants_table = grants_table.rename(columns={'metadata_grant_id': 'grant_id'})\n",
    "    grants_table.to_sql('grants', conn, if_exists='replace', index=False)\n",
    "\n",
    "    # 2. Create harmonised keywords table\n",
    "    if harmonised_keywords and 'original_keyword_mappings' in harmonised_keywords:\n",
    "        keywords_data = []\n",
    "        for mapping in harmonised_keywords['original_keyword_mappings']:\n",
    "            keywords_data.append({\n",
    "                'keyword_id': str(uuid.uuid4()),\n",
    "                'harmonised_keyword': mapping['harmonised'],\n",
    "                'original_keywords': ', '.join(mapping['original']),\n",
    "                'num_variants': len(mapping['original'])\n",
    "            })\n",
    "        keywords_df = pd.DataFrame(keywords_data)\n",
    "        keywords_df.to_sql('harmonised_keywords', conn, if_exists='replace', index=False)\n",
    "\n",
    "        # 3. Create junction table\n",
    "        keyword_id_map = dict(zip(keywords_df['harmonised_keyword'], keywords_df['keyword_id']))\n",
    "        junction_data = []\n",
    "        \n",
    "        for _, grant_row in results.iterrows():\n",
    "            grant_id = grant_row['metadata_grant_id']\n",
    "            all_harmonised_keywords = set()\n",
    "            \n",
    "            for category in ['keywords_harmonised', 'methodology_keywords_harmonised', \n",
    "                            'application_keywords_harmonised', 'technology_keywords_harmonised']:\n",
    "                if category in grant_row and grant_row[category]:\n",
    "                    all_harmonised_keywords.update(grant_row[category])\n",
    "            \n",
    "            for harmonised_kw in all_harmonised_keywords:\n",
    "                if harmonised_kw in keyword_id_map:\n",
    "                    junction_data.append({\n",
    "                        'grant_id': grant_id,\n",
    "                        'keyword_id': keyword_id_map[harmonised_kw],\n",
    "                        'harmonised_keyword': harmonised_kw\n",
    "                    })\n",
    "        \n",
    "        junction_df = pd.DataFrame(junction_data)\n",
    "        junction_df.to_sql('grant_keywords', conn, if_exists='replace', index=False)\n",
    "    \n",
    "    print(f\"✅ Database created: {db_path.absolute()}\")\n",
    "    print(f\"📊 {len(grants_table)} grants\")\n",
    "    print(f\"🏷️ {len(keywords_df)} harmonised keywords\") \n",
    "    print(f\"🔗 {len(junction_df)} grant-keyword links\")\n",
    "\n",
    "finally:\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a70de0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
